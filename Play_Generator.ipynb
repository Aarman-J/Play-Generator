{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP77wnSI7+HsY+P4IJaWsql",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aarman-J/Play-Generator/blob/main/Play_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5l3zyxsLda5",
        "outputId": "28f40d28-9196-4b6e-e54e-006d01220bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U1y_8BfL2ea",
        "outputId": "5213ffd9-94f1-473c-f990-8a6530571b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTRMX5yoL8Ac",
        "outputId": "057e4b13-4373-4d78-efb3-e596cbf64444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "text_to_int(text)\n",
        "text_as_int = text_to_int(text)"
      ],
      "metadata": {
        "id": "Cs-RJbHEMN6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        "\n",
        "print(text_as_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpLQodPqM0GV",
        "outputId": "45ba07ec-cc38-4b32-f524-b219dc19dc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18 47 56 ... 45  8  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "No4DvmRhQSIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n"
      ],
      "metadata": {
        "id": "O_Ap13R_Rrz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):  # for the example: hello\n",
        "    input_text = chunk[:-1]  # hell\n",
        "    target_text = chunk[1:]  # ello\n",
        "    return input_text, target_text  # hell, ello\n",
        "\n",
        "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry\n"
      ],
      "metadata": {
        "id": "VuT66wgkShc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print(int_to_text(x))\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47teT6GNT_VH",
        "outputId": "f92efd3d-603a-413c-e798-05f005878994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "metadata": {
        "id": "j_lSQh3fUaiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "UE2bS3vJVixc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42356fae-a3df-4f91-ee10-a1830015e852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           16640     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 65)            66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNXPJ4HcQLyN",
        "outputId": "ba533cb6-e521-431a-89ca-d3d9c01259df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R02sv7N7QQcM",
        "outputId": "93eaf46e-74ec-444c-bf08-8ff8bf85fbf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[ 5.0606476e-03  5.2575115e-03 -2.4749697e-03 ... -1.6662343e-04\n",
            "   -4.1138974e-04  7.4139098e-03]\n",
            "  [ 2.8151390e-03  2.8036321e-03 -4.5163347e-03 ... -2.5278986e-03\n",
            "   -4.7366438e-03  5.9787850e-03]\n",
            "  [ 9.5914947e-03  6.0152821e-03 -3.3542323e-03 ... -8.2857050e-03\n",
            "   -3.4505224e-03  1.5160327e-03]\n",
            "  ...\n",
            "  [-6.1307461e-03 -7.8319106e-03 -8.3166603e-03 ...  1.2931371e-02\n",
            "    3.3414273e-03 -4.7813943e-03]\n",
            "  [ 5.6294864e-04 -1.8021325e-05 -6.6970689e-03 ...  3.7074478e-03\n",
            "    1.2464256e-03 -4.9585216e-03]\n",
            "  [-4.5475727e-03  1.1958978e-03 -1.6721450e-03 ... -2.0427662e-03\n",
            "   -2.4684207e-03 -5.7352809e-03]]\n",
            "\n",
            " [[ 4.3263967e-04 -1.9867599e-03  4.2449878e-04 ... -3.5796838e-04\n",
            "    3.7634559e-04 -8.2952296e-04]\n",
            "  [-1.3915010e-03 -4.9399035e-03  6.7923189e-04 ... -6.6297839e-04\n",
            "   -7.2822901e-03  3.0900484e-03]\n",
            "  [ 6.1644986e-03 -7.0158765e-04 -8.2603563e-04 ... -6.2114219e-03\n",
            "   -6.8133976e-03 -9.6974400e-04]\n",
            "  ...\n",
            "  [ 4.0959087e-03  1.4250783e-03 -3.0982541e-03 ... -2.1803491e-03\n",
            "   -1.1000164e-02 -8.8680610e-03]\n",
            "  [ 4.4038836e-03  4.0068724e-03  2.3651011e-03 ... -3.1700800e-03\n",
            "   -9.1032144e-03 -5.2063623e-03]\n",
            "  [ 7.9241945e-05  1.5769051e-03 -2.0450638e-03 ...  1.4131162e-03\n",
            "   -8.6746821e-03 -7.5852759e-03]]\n",
            "\n",
            " [[ 4.3263967e-04 -1.9867599e-03  4.2449878e-04 ... -3.5796838e-04\n",
            "    3.7634559e-04 -8.2952296e-04]\n",
            "  [-2.0932623e-03 -8.3325217e-03  4.1532109e-04 ...  5.8836211e-03\n",
            "    2.6197564e-03  3.0589907e-03]\n",
            "  [ 3.6429060e-03 -8.1125479e-03  1.9008568e-03 ...  6.7653353e-03\n",
            "    8.5112862e-03  5.2570328e-03]\n",
            "  ...\n",
            "  [-1.3121365e-02  5.2614864e-03  1.5026950e-03 ...  5.7773818e-03\n",
            "   -9.0601975e-03 -5.6162016e-03]\n",
            "  [-5.0040567e-03  9.9941762e-03  1.0063695e-03 ... -2.3926096e-03\n",
            "   -8.6693224e-03 -6.2872777e-03]\n",
            "  [-9.3602296e-03  9.2310840e-03 -2.8508683e-03 ...  1.4676992e-03\n",
            "   -1.0074586e-02 -8.2488311e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-3.3558982e-03 -9.2776614e-04 -4.5748139e-03 ...  3.9192326e-03\n",
            "   -2.6589199e-03 -3.8549709e-03]\n",
            "  [-6.5490738e-03 -2.3298345e-03 -7.7994075e-03 ...  7.0183962e-03\n",
            "   -4.3558679e-03 -6.7940587e-03]\n",
            "  [-1.9832035e-03 -9.0765692e-03 -8.5585136e-03 ...  9.6566956e-03\n",
            "    1.4339439e-03 -7.7939876e-03]\n",
            "  ...\n",
            "  [-2.1566341e-03  5.4027708e-03 -5.9314435e-03 ... -1.3629766e-03\n",
            "   -2.8068223e-03 -1.2196975e-03]\n",
            "  [-7.1771601e-03  4.2775054e-03 -1.6618222e-03 ... -5.6672348e-03\n",
            "   -5.8278423e-03 -3.8924948e-03]\n",
            "  [-9.9607278e-03  3.4610298e-03 -1.6933794e-03 ... -3.2112109e-03\n",
            "   -6.6731013e-03 -3.3681379e-03]]\n",
            "\n",
            " [[-2.0549605e-03 -1.6760861e-03 -5.7405455e-04 ...  1.4105721e-03\n",
            "   -1.1248236e-03 -3.2817828e-04]\n",
            "  [-3.2460745e-03 -4.2806594e-03  8.5194246e-04 ... -2.5915401e-04\n",
            "   -8.9367954e-03  3.4656134e-03]\n",
            "  [-4.5004234e-04 -1.4621627e-03  4.1740965e-03 ... -1.9506477e-03\n",
            "   -8.8831931e-03  2.2996864e-03]\n",
            "  ...\n",
            "  [ 5.6813722e-03  4.1329199e-03  2.3930739e-03 ...  1.2274820e-04\n",
            "   -6.9401166e-03 -5.9934738e-03]\n",
            "  [ 4.6327794e-03  3.9672279e-03  4.5405026e-03 ...  1.5270759e-03\n",
            "   -7.8131445e-03  1.0574876e-03]\n",
            "  [ 5.9281960e-03  8.8616251e-04  3.8407980e-03 ...  5.1696161e-03\n",
            "   -7.7935429e-03 -4.1077686e-03]]\n",
            "\n",
            " [[-2.3652015e-03 -6.7636445e-03  5.3159491e-04 ...  5.2625970e-03\n",
            "    2.5573648e-03  3.4627179e-03]\n",
            "  [-7.4104569e-04 -3.4051114e-03 -7.5398886e-04 ...  7.1033835e-03\n",
            "    2.0532513e-03 -3.4881469e-03]\n",
            "  [-2.6624389e-03 -4.4589331e-03 -2.1601917e-04 ...  7.7889236e-03\n",
            "    1.7275499e-03 -2.1757851e-03]\n",
            "  ...\n",
            "  [-7.0956647e-03 -3.3197436e-03  2.5070421e-03 ...  1.0166174e-02\n",
            "   -8.7603424e-03 -3.8475210e-03]\n",
            "  [-6.4441916e-03 -3.2674237e-03  2.0648835e-03 ...  1.0993537e-02\n",
            "   -7.4133361e-03 -2.1826120e-03]\n",
            "  [-3.1447196e-03  2.6384201e-03  7.2306544e-03 ...  1.0270438e-02\n",
            "   -1.9639039e-03 -3.3760967e-03]]], shape=(64, 100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets examine one prediction\n",
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)\n",
        "# notice this is a 2d arra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGhdsY5mQZLB",
        "outputId": "5e70023a-f4da-40b8-ae37-5c012a77e41c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[ 5.0606476e-03  5.2575115e-03 -2.4749697e-03 ... -1.6662343e-04\n",
            "  -4.1138974e-04  7.4139098e-03]\n",
            " [ 2.8151390e-03  2.8036321e-03 -4.5163347e-03 ... -2.5278986e-03\n",
            "  -4.7366438e-03  5.9787850e-03]\n",
            " [ 9.5914947e-03  6.0152821e-03 -3.3542323e-03 ... -8.2857050e-03\n",
            "  -3.4505224e-03  1.5160327e-03]\n",
            " ...\n",
            " [-6.1307461e-03 -7.8319106e-03 -8.3166603e-03 ...  1.2931371e-02\n",
            "   3.3414273e-03 -4.7813943e-03]\n",
            " [ 5.6294864e-04 -1.8021325e-05 -6.6970689e-03 ...  3.7074478e-03\n",
            "   1.2464256e-03 -4.9585216e-03]\n",
            " [-4.5475727e-03  1.1958978e-03 -1.6721450e-03 ... -2.0427662e-03\n",
            "  -2.4684207e-03 -5.7352809e-03]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and finally well look at a prediction at the first timestep\n",
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)\n",
        "# and of course its 65 values re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKakI3NMQrWC",
        "outputId": "279f0b4e-5d52-4d86-9b97-dc108751222d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[ 5.0606476e-03  5.2575115e-03 -2.4749697e-03 -3.1291253e-03\n",
            "  3.5761718e-03 -6.8166014e-04 -3.9709392e-03 -1.5892304e-03\n",
            " -8.2123053e-04  1.4901401e-03 -1.7352455e-03 -7.3072151e-05\n",
            "  4.4408706e-03 -3.4606177e-04  5.8682119e-03  2.6806816e-04\n",
            "  5.4035531e-03 -4.8550370e-04  6.7099640e-03  5.6486297e-03\n",
            " -1.5628530e-03 -8.4639769e-03 -8.7481181e-05  1.2839552e-03\n",
            " -5.3569563e-03  2.0316096e-03 -4.1162875e-03 -4.7896802e-04\n",
            " -3.7107607e-03  3.2348982e-03  5.8410149e-03 -3.7090804e-03\n",
            "  6.9899706e-04  6.5741139e-03  7.4370950e-04 -4.6760226e-03\n",
            "  7.1285450e-04  1.5196821e-03  1.0644258e-03 -1.3804120e-03\n",
            " -4.8964069e-04 -2.0742305e-03 -1.0622925e-03 -3.0528412e-03\n",
            "  1.8668065e-03 -6.2716956e-04 -1.4739905e-03  1.9937204e-03\n",
            " -8.8548171e-04  4.8111589e-04  6.1415751e-03  4.5833332e-03\n",
            " -3.1908578e-03 -4.8399023e-03 -8.3953934e-04 -4.3993136e-03\n",
            "  6.6292542e-03  4.6579866e-03 -3.7597748e-04  1.3731016e-03\n",
            " -2.5514788e-03 -2.9269736e-03 -1.6662343e-04 -4.1138974e-04\n",
            "  7.4139098e-03], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars  # and this is what the model predicted for training sequence 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jznHTi2BRGkp",
        "outputId": "d79a130e-eb6a-4e50-829e-069fec230555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"McPkX&mIEro:nxjZvL'c.:Gg lHRsikTAoLoUdB.HSXPEfMS;asRph!i aEFDLFKGdJpwj-U-;!MCZWGKpD$:?QmnaVpojc;yAjh\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "HgYgcFeDR1Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "iHUm0De6R8P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gReb5relSAnW",
        "outputId": "19655fdb-2acb-4b49-c125-d5b673b16e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "172/172 [==============================] - 17s 71ms/step - loss: 2.5954\n",
            "Epoch 2/50\n",
            "172/172 [==============================] - 13s 66ms/step - loss: 1.9089\n",
            "Epoch 3/50\n",
            "172/172 [==============================] - 15s 67ms/step - loss: 1.6541\n",
            "Epoch 4/50\n",
            "172/172 [==============================] - 13s 67ms/step - loss: 1.5160\n",
            "Epoch 5/50\n",
            "172/172 [==============================] - 13s 67ms/step - loss: 1.4314\n",
            "Epoch 6/50\n",
            "172/172 [==============================] - 13s 67ms/step - loss: 1.3735\n",
            "Epoch 7/50\n",
            "172/172 [==============================] - 13s 67ms/step - loss: 1.3254\n",
            "Epoch 8/50\n",
            "172/172 [==============================] - 14s 68ms/step - loss: 1.2872\n",
            "Epoch 9/50\n",
            "172/172 [==============================] - 13s 68ms/step - loss: 1.2513\n",
            "Epoch 10/50\n",
            "172/172 [==============================] - 14s 68ms/step - loss: 1.2176\n",
            "Epoch 11/50\n",
            "172/172 [==============================] - 13s 68ms/step - loss: 1.1824\n",
            "Epoch 12/50\n",
            "172/172 [==============================] - 14s 69ms/step - loss: 1.1471\n",
            "Epoch 13/50\n",
            "172/172 [==============================] - 13s 69ms/step - loss: 1.1107\n",
            "Epoch 14/50\n",
            "172/172 [==============================] - 14s 70ms/step - loss: 1.0733\n",
            "Epoch 15/50\n",
            "172/172 [==============================] - 14s 72ms/step - loss: 1.0349\n",
            "Epoch 16/50\n",
            "172/172 [==============================] - 14s 72ms/step - loss: 0.9957\n",
            "Epoch 17/50\n",
            "172/172 [==============================] - 14s 72ms/step - loss: 0.9560\n",
            "Epoch 18/50\n",
            "172/172 [==============================] - 14s 74ms/step - loss: 0.9161\n",
            "Epoch 19/50\n",
            "172/172 [==============================] - 14s 74ms/step - loss: 0.8772\n",
            "Epoch 20/50\n",
            "172/172 [==============================] - 14s 73ms/step - loss: 0.8394\n",
            "Epoch 21/50\n",
            "172/172 [==============================] - 15s 72ms/step - loss: 0.8041\n",
            "Epoch 22/50\n",
            "172/172 [==============================] - 14s 73ms/step - loss: 0.7690\n",
            "Epoch 23/50\n",
            "172/172 [==============================] - 15s 74ms/step - loss: 0.7384\n",
            "Epoch 24/50\n",
            "172/172 [==============================] - 14s 73ms/step - loss: 0.7066\n",
            "Epoch 25/50\n",
            "172/172 [==============================] - 14s 73ms/step - loss: 0.6802\n",
            "Epoch 26/50\n",
            "172/172 [==============================] - 15s 74ms/step - loss: 0.6563\n",
            "Epoch 27/50\n",
            "172/172 [==============================] - 15s 76ms/step - loss: 0.6337\n",
            "Epoch 28/50\n",
            "172/172 [==============================] - 14s 74ms/step - loss: 0.6116\n",
            "Epoch 29/50\n",
            "172/172 [==============================] - 14s 73ms/step - loss: 0.5926\n",
            "Epoch 30/50\n",
            "172/172 [==============================] - 14s 72ms/step - loss: 0.5770\n",
            "Epoch 31/50\n",
            "172/172 [==============================] - 14s 73ms/step - loss: 0.5620\n",
            "Epoch 32/50\n",
            "172/172 [==============================] - 16s 74ms/step - loss: 0.5476\n",
            "Epoch 33/50\n",
            "172/172 [==============================] - 14s 74ms/step - loss: 0.5347\n",
            "Epoch 34/50\n",
            "172/172 [==============================] - 14s 74ms/step - loss: 0.5248\n",
            "Epoch 35/50\n",
            "172/172 [==============================] - 14s 72ms/step - loss: 0.5140\n",
            "Epoch 36/50\n",
            "172/172 [==============================] - 15s 74ms/step - loss: 0.5047\n",
            "Epoch 37/50\n",
            "172/172 [==============================] - 15s 74ms/step - loss: 0.4949\n",
            "Epoch 38/50\n",
            "172/172 [==============================] - 14s 72ms/step - loss: 0.4865\n",
            "Epoch 39/50\n",
            "172/172 [==============================] - 15s 75ms/step - loss: 0.4785\n",
            "Epoch 40/50\n",
            "172/172 [==============================] - 15s 74ms/step - loss: 0.4730\n",
            "Epoch 41/50\n",
            "172/172 [==============================] - 14s 72ms/step - loss: 0.4677\n",
            "Epoch 42/50\n",
            "172/172 [==============================] - 14s 74ms/step - loss: 0.4636\n",
            "Epoch 43/50\n",
            "172/172 [==============================] - 14s 74ms/step - loss: 0.4574\n",
            "Epoch 44/50\n",
            "172/172 [==============================] - 14s 73ms/step - loss: 0.4549\n",
            "Epoch 45/50\n",
            "172/172 [==============================] - 14s 72ms/step - loss: 0.4482\n",
            "Epoch 46/50\n",
            "172/172 [==============================] - 14s 74ms/step - loss: 0.4446\n",
            "Epoch 47/50\n",
            "172/172 [==============================] - 15s 74ms/step - loss: 0.4418\n",
            "Epoch 48/50\n",
            "172/172 [==============================] - 15s 75ms/step - loss: 0.4364\n",
            "Epoch 49/50\n",
            "172/172 [==============================] - 14s 72ms/step - loss: 0.4346\n",
            "Epoch 50/50\n",
            "172/172 [==============================] - 15s 74ms/step - loss: 0.4315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
      ],
      "metadata": {
        "id": "8BpOhdIoULmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "NlX70-T8V6oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 8000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "dAjXaa4CULpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = input(\"Type a starting string: \")\n",
        "print(generate_text(model, inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NIMNeuFULr8",
        "outputId": "375fad52-8303-4461-8ee8-3db409f42e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type a starting string: the dog died\n",
            "the dog died,\n",
            "And he mismalce shall not with me to-morrow\n",
            "And haply suitors have wed foreral,\n",
            "Before so young a tace, he's and eyed with being sleep,\n",
            "Unvil an exchmons.\n",
            "\n",
            "BRUTUS:\n",
            "Mancau shoot.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "O thou, sirrah, indeed, sir, the\n",
            "tarting of your worthy rage,\n",
            "Husband in oblivion. You are plebeix,\n",
            "That cease that thou, whosood enr,\n",
            "To lock upon partial sides, contrim ind Gaunt.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Not I, believe me: I have found the wind;\n",
            "Where he are ears with me untined fault, and so disgraced\n",
            "put on the basiness, who back to make thee offer,\n",
            "At Capulet; and when we are\n",
            "Shows her for ever. He should have none before him.\n",
            "\n",
            "ISABELLA:\n",
            "I will about to make you gainst Perchis publicly:\n",
            "how he let's do, though e the most melanch is well.\n",
            "Welcome, he hasbrace:\n",
            "I am no further like a napiliance of our garliage.\n",
            "\n",
            "MENENIUS:\n",
            "That's as much below,\n",
            "And with his virtue space I have in vain as spen.\n",
            "I never yet been st, ought show him; he must die tomorrow.\n",
            "\n",
            "Lord:\n",
            "'Tis not the master of that instant te?\n",
            "\n",
            "BIONDELLO:\n",
            "No, sir, I say unto your cheek what's thy th the banes:\n",
            "For daily and fill'd with blows: if his behold my royal father, I\n",
            "vie one, to know him any glief.\n",
            "\n",
            "Second Cit me:\n",
            "'Tis nothingy;\n",
            "For the dear state was it, with thy foes,\n",
            "Who blood should soulars 'em good deeds, writ to-day, nor your mistress,\n",
            "So shall incensell'd whither with\n",
            "Begrar in\n",
            "hope of thyself.\n",
            "\n",
            "Provost:\n",
            "God save your lordsh, look do't, and he that speaks to right sit in this am corropin!\n",
            "What are the mother, tell him there derive,\n",
            "What 'twere we lean the lute,\n",
            "To make thee never than thy face is right.\n",
            "\n",
            "ROMEO:\n",
            "I'll go along with you.\n",
            "\n",
            "Lord:\n",
            "Ox madam?\n",
            "If you not stand along?\n",
            "\n",
            "Boatswain:\n",
            "Down with him.\n",
            "\n",
            "MASTING:\n",
            "Have you noto give again\n",
            "To any time\n",
            "To have him made thee fearfully by me;\n",
            "Desire should fetch thee by the death's glory.\n",
            "I am no fire, sir, but I can ray.\n",
            "\n",
            "GLOUCESTER:\n",
            "Even whether they shall know my master Friausant thou, brave Margaret,\n",
            "Pityour strength, my uncle Clarence,\n",
            "Do level how here;\n",
            "And now 'tis faults may scarce to heavy your lordship.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "My gracious uncle Gloucester's death with bitter\n",
            "Upon my deg-vitague, what else, dear sich and lawful action: he,\n",
            "As common stranger, bound of England,\n",
            "Do as the condition of his throat; you have made remember\n",
            "With instrument me,\n",
            "Let us suffer as it was, which passion like\n",
            "A thing prince\n",
            "To struct Berolagur, and Murderer:\n",
            "How if it confounds my consent of woe?\n",
            "O God, for thy oath and the fair daughter came from sy,\n",
            "For my heart's convenient is the act of readiness so high,\n",
            "Whilst my intelligence, what art thou jeg?\n",
            "\n",
            "BIONDELLO:\n",
            "Masterless divine heirs, use the hour of death,\n",
            "I'll tell him he comes.\n",
            "\n",
            "BONNOLUMY:\n",
            "No more but sin a very noss,\n",
            "Stands against it.\n",
            "\n",
            "SICINIUS:\n",
            "Pray you, go to him!\n",
            "\n",
            "MENENIUS:\n",
            "That's likewise say so; his life is pardon:\n",
            "I ne'er said 'twere retired, a fair tre hand\n",
            "And pluck my daughter gone, as to be patience.\n",
            "\n",
            "CATESBY:\n",
            "Here, sir, as honour me in your blood\n",
            "Which his surely deal that speake the fresh wars. O, he would\n",
            "set out of the night.\n",
            "Lies the morning, are in ear by life.\n",
            "Apollo, pardon it,\n",
            "Give me the good Clarence to your royal grand.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "That's not your crossing to his master's use to Mars;\n",
            "And every grief is enemy, and wherein, or what?\n",
            "\n",
            "LUCIO:\n",
            "Why, what should you were, if the first conditable\n",
            "To break up your friends; he was not made of mine.\n",
            "\n",
            "GLOUCESTER:\n",
            "Well: what's a mock? on candam both years, like us, to bigg\n",
            "the hopeful earth that dares very little thanks.\n",
            "Harp: none, constable, what sport so bar--\n",
            "\n",
            "First Citizen:\n",
            "See, say at home; besides, or did you see the confines: nay,\n",
            "Stands a nostally take an englassion of your blood,\n",
            "Edward and Richard, night's danter\n",
            "Stand battle; no, nor one me from the goose:\n",
            "Since I am chat enemy thou hast made intended his company\n",
            "And come before a looker on.\n",
            "\n",
            "BAPTISTA:\n",
            "Now, fellow,\n",
            "What's he that knocks as he forgot!\n",
            "\n",
            "\n",
            "ENRENIUS:\n",
            "I will not sleep, there was supper theirs,\n",
            "He should.\n",
            "\n",
            "KING RICHARD II:\n",
            "Northunce, be gone.\n",
            "\n",
            "ISABELLA:\n",
            "Titus Lartius, there was some way of thine;\n",
            "Unless thou seem'st no greater power than wrong'd.\n",
            "\n",
            "BUCKINGHAM:\n",
            "And, in good time, here are enemies.\n",
            "\n",
            "SICINIUS:\n",
            "This is a bush and a smock.\n",
            "\n",
            "OXFORD:\n",
            "Clarence shall make before I do not: mark your grace?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "And wilt thou leave the king? and you must talk offendous blest\n",
            "To sound the duke ready, and we'll debe so.\n",
            "\n",
            "Second Conspirator:\n",
            "Most loyalfy rascals! God he stands in few words?\n",
            "\n",
            "SICINIUS:\n",
            "This lad and waxer it refl, one mind to tear them on?\n",
            "What matth of greatix the rebels of this fatal bade\n",
            "The weary Paris hath sent him his awhories,\n",
            "Dissembling sons, and with a ling be left, then look'd and now fill we have given for fence.\n",
            "\n",
            "MENENIUS:\n",
            "Has he done well\n",
            "The coldness of the ground, not Hide one hot,\n",
            "Should we in the base earth that thought he did\n",
            "Where I am surer divine until awry up on her!\n",
            "I am everlieves it chide as is task. If your king, is an honest man doubtful service through the world,\n",
            "By your letters, too grieve me your sword,\n",
            "And power to know like a serious tutation;\n",
            "I am in all kingdom, as he promised you; they had call\n",
            "him him his company.\n",
            "\n",
            "MENENIUS:\n",
            "How! Tranio Plantagenet, nor factious Discharina!\n",
            "Tell me this, by a crown a royal petent,\n",
            "I'll plead for humous for and serve, for one, requires\n",
            "Her eyes d feel'd\n",
            "Where he advices against thy order,\n",
            "I dream'd by words chaffed the false enforced melt.\n",
            "\n",
            "Boatswain:\n",
            "Where's Romeo's ministe?\n",
            "Conce, contain you of my conscience and my rest\n",
            "Mistress from the wite sword, uneventious compliment;\n",
            "Worse hand I of monstrally; ke'll swear:\n",
            "The burity of infament.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "My Lord! I have it two much of love?\n",
            "\n",
            "HORTENSIO:\n",
            "Sirrah, let us give us ter of the east, Histour reign,\n",
            "That love what made the tempest of your ladys;\n",
            "And live with Richmond the woman in the execution.\n",
            "A cruple, do attend on thee,\n",
            "Easing, with all duteous labours himself\n",
            "With this foul mouth did not--\n",
            "For his ofing temper's nest.\n",
            "\n",
            "ABHORSON:\n",
            "Pray, what says my lord?\n",
            "\n",
            "BUCKINGHAM:\n",
            "Dost thou deny'st thy cries?\n",
            "\n",
            "PETRUCHIO:\n",
            "Comfort, her father.\n",
            "\n",
            "Page:\n",
            "Thou preging Juliet, the condition of a damm;\n",
            "This is althus-bore mistress sending to she\n",
            "see much retire.\n",
            "\n",
            "First Citizen:\n",
            "Keeper:\n",
            "They thus saying, true toit was banish'd for your fortunes\n",
            "And hear your grievous bloody sides,\n",
            "Tidscharge him to his right dead.\n",
            "\n",
            "BIANCA:\n",
            "Sir, it is the lurew of weakness, then adore\n",
            "The unruls wing-like prant which wars: if thou dost,\n",
            "and thy answer\n",
            "With that gride thousand only son? Thy faith try while.\n",
            "O tita!\n",
            "\n",
            "POMPEY:\n",
            "O, these name\n",
            "Shall poice in name? Or else is your sister's shame,\n",
            "Remove the time to come, in wooing fair doth.\n",
            "\n",
            "KING RICHARD III:\n",
            "My lords, my arm he comes, and not disorderly resolute.\n",
            "You lie thou dost save my life? O, how is it yet\n",
            "Betrake the glorious servants have a word?\n",
            "My head and odds beyond mine armour with a short;\n",
            "Which well I know now: this is all at odns at thy father, brother,\n",
            "Though he hath done with me to stay with me:\n",
            "Uncorfort, and in London till we come to him.\n",
            "His fault thou never spoke of, or the other:\n",
            "Go token, good Camillo, and you shall follow me,\n",
            "And in the traveller of foul dust!\n",
            "\n",
            "LADY CAPULET:\n",
            "Those gracious self hath thead our person'\n",
            "\n",
            "Mayours\n",
            "That Accoulted thine only see, now hereafter warm;\n",
            "And therefore, since I cannot nt what you meet again?\n",
            "\n",
            "ROMEO:\n",
            "What is't? mine daughter? now is he what thou justly, which are\n",
            "absent to me assist you; here comes my man.\n",
            "\n",
            "MERCUTIO:\n",
            "Why, brother Plantagenet, come inquice granted up,\n",
            "Accounted Hereford's sake, for ines of the wite seems you brother is\n",
            "deceives it there must answeard, no bounty, that were jest.\n",
            "I can termant\n",
            "My father's griefs and eyes from tears distill'd\n",
            "Than shanows thy old enemies, the one has this goodly bound\n",
            "Our Rome is died; no more of your whee\n",
            "For 'twere to gat a crown,\n",
            "His eyes d see the common tears,\n",
            "Spring to the banks of graves, as time past with you down:\n",
            "That's by the dancing thought imperial himself:\n",
            "Light that pains.\n",
            "\n",
            "Nurse:\n",
            "An I'll be w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m2J62lmXULuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xhem2CEeULxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wh4ynLppULzk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}